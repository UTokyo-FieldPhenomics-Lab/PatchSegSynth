{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from options import get_arguments\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from dataset import WE3DSDataset\n",
    "from model import create_deeplabv3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class args:\n",
    "    train_images_dir = '../WE3DS_DATASET/Train/images'\n",
    "    test_images_dir = '../WE3DS_DATASET/Test/images'\n",
    "    train_segmentations_dir = '../WE3DS_DATASET/Train/annotations'\n",
    "    test_segmentations_dir = '../WE3DS_DATASET/Test/annotations'\n",
    "    \n",
    "    batch_size = 4\n",
    "    num_classes = 18\n",
    "\n",
    "transform_train = A.Compose(\n",
    "    [   \n",
    "        A.Resize(480, 640),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_val = A.Compose(\n",
    "    [   \n",
    "        A.Resize(480, 640),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = WE3DSDataset(args.train_images_dir, args.train_segmentations_dir, transform=transform_train, train=True)\n",
    "val_dataset = WE3DSDataset(args.test_images_dir, args.test_segmentations_dir, transform=transform_val, train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddgi/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ddgi/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = create_deeplabv3(args.num_classes).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\n",
    "    # 'void',\n",
    "    'soil',\n",
    "    'broad_bean',\n",
    "    'corn_spurry',\n",
    "    'red-root_amaranth',\n",
    "    'common_buckwheat',\n",
    "    'pea',\n",
    "    'red_fingergrass',\n",
    "    'common_wild_oat',\n",
    "    'cornflower',\n",
    "    'corn_cockle',\n",
    "    'corn',\n",
    "    'milk_thistle',\n",
    "    'rye_brome',\n",
    "    'soybean',\n",
    "    'sunflower',\n",
    "    'narrow-leaved_plantain',\n",
    "    'small-flower_geranium',\n",
    "    'sugar_beet'\n",
    "]\n",
    "\n",
    "# Create a mapping from class index to class name\n",
    "class_indices = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "def compute_confusion_matrix(preds, labels, num_classes):\n",
    "    preds = preds.flatten()\n",
    "    labels = labels.flatten()\n",
    "    mask = (labels >= 0) & (labels < num_classes)\n",
    "    confusion = confusion_matrix(labels[mask], preds[mask], labels=np.arange(num_classes))\n",
    "    return confusion\n",
    "\n",
    "def compute_miou(confusion):\n",
    "    intersection = np.diag(confusion)\n",
    "    ground_truth_set = confusion.sum(axis=1)\n",
    "    predicted_set = confusion.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    iou = intersection / union\n",
    "    return np.nanmean(iou), iou\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    confusion_matrix_all = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, mask, _ in dataloader:\n",
    "            img = img.to(device)\n",
    "            mask = mask.to(device)\n",
    "            outputs = model(img)['out']\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "            for pred, true_mask in zip(preds, mask):\n",
    "                # Print class indices in the original mask and their corresponding names\n",
    "                unique_classes = np.unique(true_mask)\n",
    "                confusion = compute_confusion_matrix(pred, true_mask, num_classes)\n",
    "                confusion_matrix_all += confusion\n",
    "\n",
    "    mean_iou, class_iou = compute_miou(confusion_matrix_all)\n",
    "    return mean_iou, class_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch-level synthetic dataset 5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "ckpt_path = './output/patch_level_5x/ckpt/epoch_60.pth'\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU: 0.6316171713221412, Mean IOU (exclude soil): 0.6101243663888996\n",
      "Class 0 (soil) IOU: 0.9969948551872515\n",
      "Class 1 (broad_bean) IOU: 0.6064831162431015\n",
      "Class 2 (corn_spurry) IOU: 0.49750581975390756\n",
      "Class 3 (red-root_amaranth) IOU: 0.5278951201747997\n",
      "Class 4 (common_buckwheat) IOU: 0.8788716949276759\n",
      "Class 5 (pea) IOU: 0.6632309026105385\n",
      "Class 6 (red_fingergrass) IOU: 0.6488552934532343\n",
      "Class 7 (common_wild_oat) IOU: 0.4464625054816547\n",
      "Class 8 (cornflower) IOU: 0.5931937567479517\n",
      "Class 9 (corn_cockle) IOU: 0.6860049114925776\n",
      "Class 10 (corn) IOU: 0.8920001238275083\n",
      "Class 11 (milk_thistle) IOU: 0.8798643491458885\n",
      "Class 12 (rye_brome) IOU: 0.6165264313478682\n",
      "Class 13 (soybean) IOU: 0.8569258579910619\n",
      "Class 14 (sunflower) IOU: 0.7938006538731172\n",
      "Class 15 (narrow-leaved_plantain) IOU: 0.03619309782331651\n",
      "Class 16 (small-flower_geranium) IOU: 0.3156181806845813\n",
      "Class 17 (sugar_beet) IOU: 0.43268241303250854\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "mean_iou, class_iou = evaluate_model(model, val_loader, device, 18)\n",
    "\n",
    "print(f\"Mean IOU: {mean_iou}, Mean IOU (exclude soil): {np.mean(class_iou[1:])}\")\n",
    "for i, iou in enumerate(class_iou):\n",
    "    if i != 255:  # Skip void class\n",
    "        print(f\"Class {i} ({class_indices[i]}) IOU: {iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU: 0.6809964787445622, Mean IOU (exclude soil): 0.6623694630294328\n",
      "Class 0 (soil) IOU: 0.9976557459017616\n",
      "Class 1 (broad_bean) IOU: 0.7775239513080976\n",
      "Class 2 (corn_spurry) IOU: 0.5371477756636768\n",
      "Class 3 (red-root_amaranth) IOU: 0.6262602579132474\n",
      "Class 4 (common_buckwheat) IOU: 0.9289007754835092\n",
      "Class 5 (pea) IOU: 0.7426858358961167\n",
      "Class 6 (red_fingergrass) IOU: 0.7066281843813083\n",
      "Class 7 (common_wild_oat) IOU: 0.47090604570749367\n",
      "Class 8 (cornflower) IOU: 0.6357016622904504\n",
      "Class 9 (corn_cockle) IOU: 0.6868151595338349\n",
      "Class 10 (corn) IOU: 0.8882298010122572\n",
      "Class 11 (milk_thistle) IOU: 0.9300657430201714\n",
      "Class 12 (rye_brome) IOU: 0.399595540603804\n",
      "Class 13 (soybean) IOU: 0.8692106130236403\n",
      "Class 14 (sunflower) IOU: 0.7894858954086459\n",
      "Class 15 (narrow-leaved_plantain) IOU: 0.3312119160460393\n",
      "Class 16 (small-flower_geranium) IOU: 0.40954197631596356\n",
      "Class 17 (sugar_beet) IOU: 0.5303697378920993\n"
     ]
    }
   ],
   "source": [
    "# evaluation on train data\n",
    "mean_iou, class_iou = evaluate_model(model, train_loader, device, 18)\n",
    "\n",
    "print(f\"Mean IOU: {mean_iou}, Mean IOU (exclude soil): {np.mean(class_iou[1:])}\")\n",
    "for i, iou in enumerate(class_iou):\n",
    "    if i != 255:  # Skip void class\n",
    "        print(f\"Class {i} ({class_indices[i]}) IOU: {iou}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
